\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }

\bibitem{Abadi2016}
Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M.,
  Ghemawat, S., Irving, G., Isard, M., Kudlur, M., Levenberg, J., Monga, R.,
  Moore, S., Murray, D.G., Steiner, B., Tucker, P., Vasudevan, V., Warden, P.,
  Wicke, M., Yu, Y., Zheng, X., Brain, G.: {TensorFlow: A System for
  Large-Scale Machine Learning TensorFlow: A system for large-scale machine
  learning}. In: 12th USENIX Symposium on Operating Systems Design and
  Implementation (OSDI '16). pp. 265--284 (2016),
  \url{https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi}

\bibitem{baselines}
Dhariwal, P., Hesse, C., Klimov, O., Nichol, A., Plappert, M., Radford, A.,
  Schulman, J., Sidor, S., Wu, Y.: {OpenAI Baselines}.
  $\backslash$url{\{}https://github.com/openai/baselines{\}} (2017)

\bibitem{DBLP:journals/corr/FoersterAFW16a}
Foerster, J.N., Assael, Y.M., de~Freitas, N., Whiteson, S.: {Learning to
  Communicate with Deep Multi-Agent Reinforcement Learning}. CoRR  abs/1605.0
  (2016), \url{http://arxiv.org/abs/1605.06676}

\bibitem{Foerster2017}
Foerster, J.N., Nardelli, N., Farquhar, G., Torr, P.H.S., Kohli, P., Whiteson,
  S.: {Stabilising Experience Replay for Deep Multi-Agent Reinforcement
  Learning}. CoRR  abs/1702.0 (2017), \url{http://arxiv.org/abs/1702.08887}

\bibitem{Gao2017}
Gao, J., Shen, Y., Liu, J., Ito, M., Shiratori, N.: {Adaptive Traffic Signal
  Control: Deep Reinforcement Learning Algorithm with Experience Replay and
  Target Network}. arXiv pp. 1--10 (2017),
  \url{https://arxiv.org/pdf/1705.02755.pdf{\%}0Ahttp://arxiv.org/abs/1705.02755}

\bibitem{Hasselt:2016:DRL:3016100.3016191}
van Hasselt, H., Guez, A., Silver, D.: {Deep Reinforcement Learning with Double
  Q-Learning}. In: Proceedings of the Thirtieth AAAI Conference on Artificial
  Intelligence. pp. 2094--2100. AAAI'16, AAAI Press (2016),
  \url{http://dl.acm.org/citation.cfm?id=3016100.3016191}

\bibitem{Hasselt2010}
Hasselt, H.V., Group, A.C., Wiskunde, C.: {Double Q-learning}. Nips pp. 1--9
  (2010)

\bibitem{SUMO2012}
Krajzewicz, D., Erdmann, J., Behrisch, M., Bieker, L.: {Recent Development and
  Applications of {\{}SUMO - Simulation of Urban MObility{\}}}. International
  Journal On Advances in Systems and Measurements  5(3{\&}4),  128--138 (dec
  2012), \url{http://elib.dlr.de/80483/}

\bibitem{Liang2018}
Liang, X., Du, X., Wang, G., Han, Z.: {Deep Reinforcement Learning for Traffic
  Light Control in Vehicular Networks}. Ieee Transactions on Vehicular
  Technology  1(Xx),  1--11 (2018), \url{https://arxiv.org/pdf/1803.11115.pdf}

\bibitem{Liu2017CooperativeDR}
Liu, M., Deng, J., Xu, M., Zhang, X., Wang, W.: {Cooperative Deep Reinforcement
  Learning for Traffic Signal Control}. 23rd ACM SIGKDD Conference on Knowledge
  Discovery and Data Mining (KDD), Halifax 2017  (2017)

\bibitem{Mnih2015}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G.,
  Graves, A., Riedmiller, M., Fidjeland, A.K., Ostrovski, G., Petersen, S.,
  Beattie, C., Sadik, A., Antonoglou, I., King, H., Kumaran, D., Wierstra, D.,
  Legg, S., Hassabis, D.: {Human-level control through deep reinforcement
  learning}. Nature  518(7540),  529--533 (2015)

\bibitem{RichardS.SuttonandAndrewG.Barto2018}
{Richard S. Sutton and Andrew G. Barto}: {Reinforcement Learning, Second
  Edition An Introduction}. MIT Press, second edi edn. (2018)

\bibitem{SchaulQAS15}
Schaul, T., Quan, J., Antonoglou, I., Silver, D.: Prioritized experience
  replay. CoRR  abs/1511.05952 (2015), \url{http://arxiv.org/abs/1511.05952}

\bibitem{Tampuu2015}
Tampuu, A., Matiisen, T., Kodelja, D., Kuzovkin, I., Korjus, K., Aru, J., Aru,
  J., Vicente, R.: {Multiagent Cooperation and Competition with Deep
  Reinforcement Learning}. arXiv pp. 1--12 (2015),
  \url{http://arxiv.org/abs/1511.08779}

\bibitem{Tan1993}
Tan, M.: {Multi-Agent Reinforcement Learning: Independent vs. Cooperative
  Agents}. In: Machine Learning Proceedings 1993, pp. 330--337. Morgan Kaufmann
  Publishers Inc. (1993),
  \url{http://linkinghub.elsevier.com/retrieve/pii/B9781558603073500496}

\bibitem{VanDerPol2016}
{Van Der Pol}, E., Oliehoek, F.A.: {Coordinated Deep Reinforcement Learners for
  Traffic Light Control}. NIPS'16 Workshop on Learning, Inference and Control
  of Multi-Agent Systems (Nips) (2016),
  \url{http://www.fransoliehoek.net/docs/VanDerPol16LICMAS.pdf{\%}0Ahttp://elisevanderpol.nl/papers/vanderpol{\_}oliehoek{\_}nipsmalic2016.pdf}

\bibitem{Wang2016}
Wang, Z., de~Freitas, N., Lanctot, M.: {Dueling Network Architectures for Deep
  Reinforcement Learning}. arXiv (9),  1--16 (2016),
  \url{http://arxiv.org/abs/1511.06581}

\bibitem{Watkins1992}
Watkins, C.J.C.H., Dayan, P.: {Q-learning}. Machine Learning  8(3-4),  279--292
  (1992), \url{http://link.springer.com/10.1007/BF00992698}

\end{thebibliography}
